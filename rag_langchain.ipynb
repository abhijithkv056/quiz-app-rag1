{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_community.document_loaders import (\n",
    "    WebBaseLoader, \n",
    "    PyPDFLoader, \n",
    "    Docx2txtLoader,\n",
    ")\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "os.environ[\"USER_AGENT\"] = \"MyFastAPIApp/1.0\"\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load docs\n",
    "\n",
    "doc_paths = [\n",
    "    \"docs/Abhijith-Kotak Resume-AI Engineer role.pdf\"\n",
    "]\n",
    "\n",
    "docs = [] \n",
    "for doc_file in doc_paths:\n",
    "    file_path = Path(doc_file)\n",
    "\n",
    "    try:\n",
    "        if doc_file.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif doc_file.endswith(\".docx\"):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif doc_file.endswith(\".txt\") or doc_file.name.endswith(\".md\"):\n",
    "            loader = TextLoader(file_path)\n",
    "        else:\n",
    "            print(f\"Document type {doc_file.type} not supported.\")\n",
    "            continue\n",
    "\n",
    "        docs.extend(loader.load())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading document {doc_file.name}: {e}\")\n",
    "\n",
    "\n",
    "# Load URLs\n",
    "\n",
    "url = \"https://docs.streamlit.io/develop/quick-reference/release-notes\"\n",
    "try:\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading document from {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'docs\\\\Abhijith-Kotak Resume-AI Engineer role.pdf', 'page': 0}, page_content='Abhijith  K V ‚Äì Data Scientist  Resume  \\nabhijithkv56@gmail.com  | 9321670581  |GitHub: https://github.com/abhijithkv056  \\n \\nACADEMIC PROFILE  \\n \\nIIT Madras ,                     Bachelor of Technology (B. Tech) , CGPA  7.58 /10  \\nIJPS School, Kerala                   Class XII ‚Äì Computer Science , CGPA 9.4 / 10  \\n \\nWORK EXPERI ENCE \\n \\nData Scientist                Nine Stacks Gaming LLP (Internship)    Nov 2020 ‚Äì Feb 2021 \\n \\n‚Ä¢ Experienced in Build, train and deploy Machine Learning Models  and working in production  environment setup.  \\n‚Ä¢ Conceptualized  a machine learning Forecasting model  using XG Boost  to predict the customer  lifetime  \\nvalue for helping to improving customer retention taking decisions on customized gamification.  \\n‚Ä¢ Conceptualized a flag system  to improve the identify early dropout user  saving ~ 15% reward points spend  \\n‚Ä¢ Proficient in  SQL, and in Python  libraries like NumPy and Pandas  for data manipulation, Statistics and data transformation  \\ninto actionable recommendations  utilizing Data Visualization libraries like Matplotlib  \\nFamiliarity with Cloud based AWS  tools like S3, EC2 AWS Lambda, Amazon Redshift, AWS SageMaker  & version control via Git  \\n \\nManage r, BSG ‚Äì Retail Liabilities     Kotak Mahindra Bank Limited           July 2022 ‚Äì Present  \\n \\n‚Ä¢ Performed Exploratory Data Analysis  on customer behaviour during onboarding and identified a financial loss of 25 Lakhs  on \\nKotak CA journey due to customer drop -off in Funding page . Proficient in using Python  and SQL for data analytics  \\n‚Ä¢ Handled the Software Development & delivery Life cy cle and associated  with development of Kotak CA onboarding product.  \\n‚Ä¢ Experienc ed with Agile development methodology using Azure DevOps . Worked with AWS  services like S3, DynamoDB etc.  \\n‚Ä¢ Collaborated with the SDE team to enhance software reliability performing  QA tasks, including API and integration testing  \\n‚Ä¢ Apt at Mirco -services, data bases  and API integrations done for Kotak Unified CA. worked on testing to ensure reliability  \\n‚Ä¢ Received awards and commendation from senior management for exemplar performance in contributing towards a record of \\n50,000  Kotak Digital Current Account customers onboarded 3 months through the digital platform built inhouse  \\n \\nPORTFOLIO AND PROJECTS  \\n \\nLLM & Gen AI       Q&A RAG based Chatbot   - Live Link     Project link:  GitHub  \\n‚Ä¢ Developed  and deployed  an End to End Chatbot appl ication  using Lang chain framework fo r users \\nto and ask question about with context to the data uploaded with RAG . Utilized both Open AI \\ngpt-4o & Anthropic Claude -sonnet -3.5 model for LLM inference  and vector emb eddings  \\n‚Ä¢ Utilized Streamlit  for creating user interfac e. Explore various avenues of Finetuning  model response \\nvia Prompt Engineerin g to improve model performance.  \\n‚Ä¢ Implemented  production  ready code  and applied CI-CD pipelines for the project. The application also  \\nallows  multiple users to simultaneously use the application  via unique  session id   \\n \\nPredictive Analytics   Propensity Modelling ‚Äì Product purchase  project      \\n \\n‚Ä¢ Engineered a Propensity model  using SVM & XG Boost  model for product purchase based on customer \\nbehaviour on product page . The model accurately classif ied nearly 8 8% of the prospective customers.  \\n‚Ä¢ Apt in utilizing feature engineering, normalization and dimensionality reduction techniques such as PCA \\n \\nNLP Project         Chatbot - Customer Intent Prediction                   \\n \\n‚Ä¢ Showcased  a model  for a Chat bot  Intent prediction  NLP project using Random Forest  Classification  \\nmodel  ‚Äìto assist agents for easy flagging of negative response given by customer.   \\n‚Ä¢ Leveraged NLP techniques  for projects involving d ata extraction, Name Entity Recognition (NER), \\nSentiment analysis, Information retrieval. Proficient in NLTK, Gensim, Spacy, regex, TF -IDF for the same  \\n \\nTime Series Project   Hourly  Call volume forecasting Projec t            \\n‚Ä¢ Expertise in working with Time series data  and feature extraction & data transformation techniques  \\n‚Ä¢ Implemented a forecasting model  for customer call volume prediction in call center  \\n‚Ä¢ Utilized Lasso and Ridge regression to achieve the same. Compared performance with ARIMA  & LSTM  \\n \\n \\nRELEVANT SKILL S \\n‚Ä¢ Highlights : Python, SQL, Data analytics, NLP, Time series, TensorFlow, Pytorch,  Langchain, OpenAI, Open Source, Hugging face  \\n‚Ä¢ Others:  Git, version control, Pandas, NumPy, NLTK , scikit -learn, XG Boost, Decision Tree, Linear regression, GPT, Keras, BERT , \\nLogistic  regression, feature engineering, Hypothesis testing, Gradient descent, Probability, Statistics, Transformers , Develop, train, \\nand evaluate predictive AI models , Deploy models into production environments , monitoring, Structured and unstructured data  '),\n",
       " Document(metadata={'source': 'https://docs.streamlit.io/develop/quick-reference/release-notes', 'title': 'Release notes - Streamlit Docs', 'description': 'A changelog of highlights and fixes for each version of Streamlit.', 'language': 'No language found.'}, page_content=\"Release notes - Streamlit DocsDocumentationsearchSearchrocket_launchGet startedInstallationaddFundamentalsaddFirst stepsaddcodeDevelopConceptsaddAPI referenceaddTutorialsaddQuick referenceremoveCheat sheetRelease notesremove2025202420232022202120202019Pre-release featuresRoadmapopen_in_newweb_assetDeployConceptsaddStreamlit Community CloudaddSnowflakeOther platformsaddschoolKnowledge baseFAQInstalling dependenciesDeployment issuesHome/Develop/Quick reference/Release notesRelease notes\\nThis page lists highlights, bug fixes, and known issues for the latest release of Streamlit. If you're looking for information about nightly releases or experimental features, see Pre-release features.\\nUpgrade Streamlit\\nstarTipTo upgrade to the latest version of Streamlit, run:pip install --upgrade streamlit\\n\\nVersion 1.42.0 (latest)\\nRelease date: February 4, 2025\\nHighlights\\n\\nüë©\\u200düíª\\xa0Introducing st.login() and st.logout() to authenticate users with any OpenID Connect provider.\\n\\nNotable Changes\\n\\n‚ù£Ô∏è\\xa0st.table supports Markdown (#8785, #10088).\\n‚è≤Ô∏è\\xa0st.spinner can show elapsed time with show_time=True (#6805, #10072).\\nüíà\\xa0st.image supports Markdown in the caption parameter (#6808, #10075).\\n‚ÜïÔ∏è\\xa0st.code has a height parameter (#7418, #10080).\\n‚ÜîÔ∏è\\xa0Most charts default to using use_container_width=True (#10064).\\n‚ùÑÔ∏è\\xa0SnowflakeConnection was updated to match the current Snowflake API, which changes its handling of keyword arguments in some cases (#10122).\\nüêÅ\\xa0Users can drag and drop dataframe columns to rearrange them (#8796, #10099).\\n\\nOther Changes\\n\\nüìå\\xa0Dataframes have column menus for users to sort and pin columns (#10206).\\nüö¶\\xa0Dataframes support categorical indices (#9647, #10195).\\nüõ∏\\xa0Dataframes show a hover highlight on rows (#8096, #10104).\\n‚ö†Ô∏è\\xa0When dataframes have cell values that are inconsistent with their configured type, Streamlit shows a tooltip describing the error (#8253, #9899).\\n‚û∞ If there is an existing asyncio event loop when a Streamlit app starts, the app will reuse it instead of creating a new one (#10164). Thanks, DeltaGa!\\nüñºÔ∏è\\xa0Streamlit recognizes pyspark.sql.connect.dataframe.DataFrame objects as dataframes (#9953, #9954). Thanks, OSalama!\\nüòÉ\\xa0We've updated emoji validation for new emojis (#10149).\\nüî£\\xa0Material Symbols have been updated with the latest icons (#10247).\\nüíÖ\\xa0Visual tweaks and improvements (#8705, #9823, #10047, #10048, #10083, #10087, #10225).\\n‚≠ï\\xa0st.image displays rounded corners for consistent design (#9999).\\nüé©\\xa0Bug fix: Top margin is applied correctly in st.columns (#10265, #10268).\\nüí©\\xa0Bug fix: react-syntax-highlighter is aliased to prevent rendering errors in st.code (#10231, #10244).\\nüßπ\\xa0Bug fix: We improved error messages for st.query_params (#10111, #10237).\\nü™±\\xa0Bug fix: Linting for st.altair_chart recognizes all Altair chart types (#10202).\\n‚ÜóÔ∏è\\xa0Bug fix: st.dataframe supports raw Arrow data (#5606, #10191).\\nüêç\\xa0Bug fix: st.navigation and st.page_link work when running in pure Python tests (#10163).\\n‚ò†Ô∏è\\xa0Bug fix: Retries were added to prevent a possible race condition when files are removed while Streamlit is running (#10148).\\nüëΩ\\xa0Bug fix: When printing an app, st.logo will only print once (#10165, #10171).\\nüåç\\xa0Bug fix: Material icons are marked to prevent translation (#10168, #10174).\\nüëª\\xa0Bug fix: st.vega_lite_chart correctly caches and updates its data (#6689, #10125).\\nü¶Ä\\xa0Bug fix: When a fragment ID is not found, Streamlit logs a warning but doesn't raise an error (#9921, #10130).\\nü¶ã\\xa0Bug fix: The label on st.expander correctly fades when stale (#10085).\\nü¶é\\xa0Bug fix: st.date_input provides better type hinting for its return value (#9477, #9620). Thanks, pranaybattu!\\nüêå\\xa0Bug fix: In dataframes, small float values display their first significant figure instead of displaying as 0 (#10060).\\nüï∏Ô∏è\\xa0Bug fix: When rich is installed, errors are only logged once. (#10097).\\nü¶ó\\xa0Bug fix: st.text preserves whitespace (#10055, #10062).\\nü¶Ç\\xa0Bug fix: Dataframe width is not ignored when height is changed (#9762, #10036).\\nü¶ü\\xa0Bug fix: Multi index columns correctly handle empty labels (#9749, #10035).\\nü¶†\\xa0Bug fix: Pinned columns respect column_order in when configured in st.dataframe (#9997, #10034).\\nü™∞\\xa0Bug fix: Tooltips don't overflow to the left or right (#9288, #9452, #9983).\\nü™≥\\xa0Bug fix: Disabled feedback widgets correctly show their value (#10030).\\nüï∑Ô∏è\\xa0Bug fix: Widgets correctly submit values if a user edits the value and immediately clicks a button (#10007, #10018).\\nüêû\\xa0Bug fix: Some MIME types have been hardcoded to protect against browser misconfiguration (#10004, #10010).\\nüêù\\xa0Bug fix: Files that unnecessarily inflated Streamlit's installation size were removed (#10008, #10011).\\nüêú\\xa0Bug fix: st.date_input gives the correct type hint for the value parameter (#10005, #10006).\\nü™≤\\xa0Bug fix: st.write passes to st.html when ._repr_html() is present for an object (#9910).\\nüêõ\\xa0Bug fix: st.html preserves target=_blank if set in an HTML string (#9972, #9994).\\n\\nOlder versions of Streamlit\\n\\n2024 release notes\\n2023 release notes\\n2022 release notes\\n2021 release notes\\n2020 release notes\\n2019 release notes\\nPrevious: Cheat sheetNext: 2025forumStill have questions?Our forums are full of helpful information and Streamlit experts.HomeContact UsCommunity¬© 2025 Snowflake Inc.Cookie policyforum Ask AI\")]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'docs\\\\Abhijith-Kotak Resume-AI Engineer role.pdf', 'page': 0}, page_content='Abhijith  K V ‚Äì Data Scientist  Resume  \\nabhijithkv56@gmail.com  | 9321670581  |GitHub: https://github.com/abhijithkv056  \\n \\nACADEMIC PROFILE  \\n \\nIIT Madras ,                     Bachelor of Technology (B. Tech) , CGPA  7.58 /10  \\nIJPS School, Kerala                   Class XII ‚Äì Computer Science , CGPA 9.4 / 10  \\n \\nWORK EXPERI ENCE \\n \\nData Scientist                Nine Stacks Gaming LLP (Internship)    Nov 2020 ‚Äì Feb 2021 \\n \\n‚Ä¢ Experienced in Build, train and deploy Machine Learning Models  and working in production  environment setup.  \\n‚Ä¢ Conceptualized  a machine learning Forecasting model  using XG Boost  to predict the customer  lifetime  \\nvalue for helping to improving customer retention taking decisions on customized gamification.  \\n‚Ä¢ Conceptualized a flag system  to improve the identify early dropout user  saving ~ 15% reward points spend  \\n‚Ä¢ Proficient in  SQL, and in Python  libraries like NumPy and Pandas  for data manipulation, Statistics and data transformation'),\n",
       " Document(metadata={'source': 'docs\\\\Abhijith-Kotak Resume-AI Engineer role.pdf', 'page': 0}, page_content='‚Ä¢ Proficient in  SQL, and in Python  libraries like NumPy and Pandas  for data manipulation, Statistics and data transformation  \\ninto actionable recommendations  utilizing Data Visualization libraries like Matplotlib  \\nFamiliarity with Cloud based AWS  tools like S3, EC2 AWS Lambda, Amazon Redshift, AWS SageMaker  & version control via Git  \\n \\nManage r, BSG ‚Äì Retail Liabilities     Kotak Mahindra Bank Limited           July 2022 ‚Äì Present  \\n \\n‚Ä¢ Performed Exploratory Data Analysis  on customer behaviour during onboarding and identified a financial loss of 25 Lakhs  on \\nKotak CA journey due to customer drop -off in Funding page . Proficient in using Python  and SQL for data analytics  \\n‚Ä¢ Handled the Software Development & delivery Life cy cle and associated  with development of Kotak CA onboarding product.  \\n‚Ä¢ Experienc ed with Agile development methodology using Azure DevOps . Worked with AWS  services like S3, DynamoDB etc.'),\n",
       " Document(metadata={'source': 'docs\\\\Abhijith-Kotak Resume-AI Engineer role.pdf', 'page': 0}, page_content='‚Ä¢ Experienc ed with Agile development methodology using Azure DevOps . Worked with AWS  services like S3, DynamoDB etc.  \\n‚Ä¢ Collaborated with the SDE team to enhance software reliability performing  QA tasks, including API and integration testing  \\n‚Ä¢ Apt at Mirco -services, data bases  and API integrations done for Kotak Unified CA. worked on testing to ensure reliability  \\n‚Ä¢ Received awards and commendation from senior management for exemplar performance in contributing towards a record of \\n50,000  Kotak Digital Current Account customers onboarded 3 months through the digital platform built inhouse  \\n \\nPORTFOLIO AND PROJECTS  \\n \\nLLM & Gen AI       Q&A RAG based Chatbot   - Live Link     Project link:  GitHub  \\n‚Ä¢ Developed  and deployed  an End to End Chatbot appl ication  using Lang chain framework fo r users \\nto and ask question about with context to the data uploaded with RAG . Utilized both Open AI'),\n",
       " Document(metadata={'source': 'docs\\\\Abhijith-Kotak Resume-AI Engineer role.pdf', 'page': 0}, page_content='‚Ä¢ Developed  and deployed  an End to End Chatbot appl ication  using Lang chain framework fo r users \\nto and ask question about with context to the data uploaded with RAG . Utilized both Open AI \\ngpt-4o & Anthropic Claude -sonnet -3.5 model for LLM inference  and vector emb eddings  \\n‚Ä¢ Utilized Streamlit  for creating user interfac e. Explore various avenues of Finetuning  model response \\nvia Prompt Engineerin g to improve model performance.  \\n‚Ä¢ Implemented  production  ready code  and applied CI-CD pipelines for the project. The application also  \\nallows  multiple users to simultaneously use the application  via unique  session id   \\n \\nPredictive Analytics   Propensity Modelling ‚Äì Product purchase  project      \\n \\n‚Ä¢ Engineered a Propensity model  using SVM & XG Boost  model for product purchase based on customer \\nbehaviour on product page . The model accurately classif ied nearly 8 8% of the prospective customers.'),\n",
       " Document(metadata={'source': 'docs\\\\Abhijith-Kotak Resume-AI Engineer role.pdf', 'page': 0}, page_content='behaviour on product page . The model accurately classif ied nearly 8 8% of the prospective customers.  \\n‚Ä¢ Apt in utilizing feature engineering, normalization and dimensionality reduction techniques such as PCA \\n \\nNLP Project         Chatbot - Customer Intent Prediction                   \\n \\n‚Ä¢ Showcased  a model  for a Chat bot  Intent prediction  NLP project using Random Forest  Classification  \\nmodel  ‚Äìto assist agents for easy flagging of negative response given by customer.   \\n‚Ä¢ Leveraged NLP techniques  for projects involving d ata extraction, Name Entity Recognition (NER), \\nSentiment analysis, Information retrieval. Proficient in NLTK, Gensim, Spacy, regex, TF -IDF for the same  \\n \\nTime Series Project   Hourly  Call volume forecasting Projec t            \\n‚Ä¢ Expertise in working with Time series data  and feature extraction & data transformation techniques  \\n‚Ä¢ Implemented a forecasting model  for customer call volume prediction in call center'),\n",
       " Document(metadata={'source': 'docs\\\\Abhijith-Kotak Resume-AI Engineer role.pdf', 'page': 0}, page_content='‚Ä¢ Expertise in working with Time series data  and feature extraction & data transformation techniques  \\n‚Ä¢ Implemented a forecasting model  for customer call volume prediction in call center  \\n‚Ä¢ Utilized Lasso and Ridge regression to achieve the same. Compared performance with ARIMA  & LSTM  \\n \\n \\nRELEVANT SKILL S \\n‚Ä¢ Highlights : Python, SQL, Data analytics, NLP, Time series, TensorFlow, Pytorch,  Langchain, OpenAI, Open Source, Hugging face  \\n‚Ä¢ Others:  Git, version control, Pandas, NumPy, NLTK , scikit -learn, XG Boost, Decision Tree, Linear regression, GPT, Keras, BERT , \\nLogistic  regression, feature engineering, Hypothesis testing, Gradient descent, Probability, Statistics, Transformers , Develop, train, \\nand evaluate predictive AI models , Deploy models into production environments , monitoring, Structured and unstructured data'),\n",
       " Document(metadata={'source': 'https://docs.streamlit.io/develop/quick-reference/release-notes', 'title': 'Release notes - Streamlit Docs', 'description': 'A changelog of highlights and fixes for each version of Streamlit.', 'language': 'No language found.'}, page_content=\"Release notes - Streamlit DocsDocumentationsearchSearchrocket_launchGet startedInstallationaddFundamentalsaddFirst stepsaddcodeDevelopConceptsaddAPI referenceaddTutorialsaddQuick referenceremoveCheat sheetRelease notesremove2025202420232022202120202019Pre-release featuresRoadmapopen_in_newweb_assetDeployConceptsaddStreamlit Community CloudaddSnowflakeOther platformsaddschoolKnowledge baseFAQInstalling dependenciesDeployment issuesHome/Develop/Quick reference/Release notesRelease notes\\nThis page lists highlights, bug fixes, and known issues for the latest release of Streamlit. If you're looking for information about nightly releases or experimental features, see Pre-release features.\\nUpgrade Streamlit\\nstarTipTo upgrade to the latest version of Streamlit, run:pip install --upgrade streamlit\\n\\nVersion 1.42.0 (latest)\\nRelease date: February 4, 2025\\nHighlights\\n\\nüë©\\u200düíª\\xa0Introducing st.login() and st.logout() to authenticate users with any OpenID Connect provider.\\n\\nNotable Changes\"),\n",
       " Document(metadata={'source': 'https://docs.streamlit.io/develop/quick-reference/release-notes', 'title': 'Release notes - Streamlit Docs', 'description': 'A changelog of highlights and fixes for each version of Streamlit.', 'language': 'No language found.'}, page_content='Version 1.42.0 (latest)\\nRelease date: February 4, 2025\\nHighlights\\n\\nüë©\\u200düíª\\xa0Introducing st.login() and st.logout() to authenticate users with any OpenID Connect provider.\\n\\nNotable Changes\\n\\n‚ù£Ô∏è\\xa0st.table supports Markdown (#8785, #10088).\\n‚è≤Ô∏è\\xa0st.spinner can show elapsed time with show_time=True (#6805, #10072).\\nüíà\\xa0st.image supports Markdown in the caption parameter (#6808, #10075).\\n‚ÜïÔ∏è\\xa0st.code has a height parameter (#7418, #10080).\\n‚ÜîÔ∏è\\xa0Most charts default to using use_container_width=True (#10064).\\n‚ùÑÔ∏è\\xa0SnowflakeConnection was updated to match the current Snowflake API, which changes its handling of keyword arguments in some cases (#10122).\\nüêÅ\\xa0Users can drag and drop dataframe columns to rearrange them (#8796, #10099).\\n\\nOther Changes'),\n",
       " Document(metadata={'source': 'https://docs.streamlit.io/develop/quick-reference/release-notes', 'title': 'Release notes - Streamlit Docs', 'description': 'A changelog of highlights and fixes for each version of Streamlit.', 'language': 'No language found.'}, page_content=\"üìå\\xa0Dataframes have column menus for users to sort and pin columns (#10206).\\nüö¶\\xa0Dataframes support categorical indices (#9647, #10195).\\nüõ∏\\xa0Dataframes show a hover highlight on rows (#8096, #10104).\\n‚ö†Ô∏è\\xa0When dataframes have cell values that are inconsistent with their configured type, Streamlit shows a tooltip describing the error (#8253, #9899).\\n‚û∞ If there is an existing asyncio event loop when a Streamlit app starts, the app will reuse it instead of creating a new one (#10164). Thanks, DeltaGa!\\nüñºÔ∏è\\xa0Streamlit recognizes pyspark.sql.connect.dataframe.DataFrame objects as dataframes (#9953, #9954). Thanks, OSalama!\\nüòÉ\\xa0We've updated emoji validation for new emojis (#10149).\\nüî£\\xa0Material Symbols have been updated with the latest icons (#10247).\\nüíÖ\\xa0Visual tweaks and improvements (#8705, #9823, #10047, #10048, #10083, #10087, #10225).\\n‚≠ï\\xa0st.image displays rounded corners for consistent design (#9999).\\nüé©\\xa0Bug fix: Top margin is applied correctly in st.columns (#10265, #10268).\"),\n",
       " Document(metadata={'source': 'https://docs.streamlit.io/develop/quick-reference/release-notes', 'title': 'Release notes - Streamlit Docs', 'description': 'A changelog of highlights and fixes for each version of Streamlit.', 'language': 'No language found.'}, page_content='‚≠ï\\xa0st.image displays rounded corners for consistent design (#9999).\\nüé©\\xa0Bug fix: Top margin is applied correctly in st.columns (#10265, #10268).\\nüí©\\xa0Bug fix: react-syntax-highlighter is aliased to prevent rendering errors in st.code (#10231, #10244).\\nüßπ\\xa0Bug fix: We improved error messages for st.query_params (#10111, #10237).\\nü™±\\xa0Bug fix: Linting for st.altair_chart recognizes all Altair chart types (#10202).\\n‚ÜóÔ∏è\\xa0Bug fix: st.dataframe supports raw Arrow data (#5606, #10191).\\nüêç\\xa0Bug fix: st.navigation and st.page_link work when running in pure Python tests (#10163).\\n‚ò†Ô∏è\\xa0Bug fix: Retries were added to prevent a possible race condition when files are removed while Streamlit is running (#10148).\\nüëΩ\\xa0Bug fix: When printing an app, st.logo will only print once (#10165, #10171).\\nüåç\\xa0Bug fix: Material icons are marked to prevent translation (#10168, #10174).\\nüëª\\xa0Bug fix: st.vega_lite_chart correctly caches and updates its data (#6689, #10125).'),\n",
       " Document(metadata={'source': 'https://docs.streamlit.io/develop/quick-reference/release-notes', 'title': 'Release notes - Streamlit Docs', 'description': 'A changelog of highlights and fixes for each version of Streamlit.', 'language': 'No language found.'}, page_content=\"üåç\\xa0Bug fix: Material icons are marked to prevent translation (#10168, #10174).\\nüëª\\xa0Bug fix: st.vega_lite_chart correctly caches and updates its data (#6689, #10125).\\nü¶Ä\\xa0Bug fix: When a fragment ID is not found, Streamlit logs a warning but doesn't raise an error (#9921, #10130).\\nü¶ã\\xa0Bug fix: The label on st.expander correctly fades when stale (#10085).\\nü¶é\\xa0Bug fix: st.date_input provides better type hinting for its return value (#9477, #9620). Thanks, pranaybattu!\\nüêå\\xa0Bug fix: In dataframes, small float values display their first significant figure instead of displaying as 0 (#10060).\\nüï∏Ô∏è\\xa0Bug fix: When rich is installed, errors are only logged once. (#10097).\\nü¶ó\\xa0Bug fix: st.text preserves whitespace (#10055, #10062).\\nü¶Ç\\xa0Bug fix: Dataframe width is not ignored when height is changed (#9762, #10036).\\nü¶ü\\xa0Bug fix: Multi index columns correctly handle empty labels (#9749, #10035).\\nü¶†\\xa0Bug fix: Pinned columns respect column_order in when configured in st.dataframe (#9997, #10034).\"),\n",
       " Document(metadata={'source': 'https://docs.streamlit.io/develop/quick-reference/release-notes', 'title': 'Release notes - Streamlit Docs', 'description': 'A changelog of highlights and fixes for each version of Streamlit.', 'language': 'No language found.'}, page_content=\"ü¶ü\\xa0Bug fix: Multi index columns correctly handle empty labels (#9749, #10035).\\nü¶†\\xa0Bug fix: Pinned columns respect column_order in when configured in st.dataframe (#9997, #10034).\\nü™∞\\xa0Bug fix: Tooltips don't overflow to the left or right (#9288, #9452, #9983).\\nü™≥\\xa0Bug fix: Disabled feedback widgets correctly show their value (#10030).\\nüï∑Ô∏è\\xa0Bug fix: Widgets correctly submit values if a user edits the value and immediately clicks a button (#10007, #10018).\\nüêû\\xa0Bug fix: Some MIME types have been hardcoded to protect against browser misconfiguration (#10004, #10010).\\nüêù\\xa0Bug fix: Files that unnecessarily inflated Streamlit's installation size were removed (#10008, #10011).\\nüêú\\xa0Bug fix: st.date_input gives the correct type hint for the value parameter (#10005, #10006).\\nü™≤\\xa0Bug fix: st.write passes to st.html when ._repr_html() is present for an object (#9910).\\nüêõ\\xa0Bug fix: st.html preserves target=_blank if set in an HTML string (#9972, #9994).\"),\n",
       " Document(metadata={'source': 'https://docs.streamlit.io/develop/quick-reference/release-notes', 'title': 'Release notes - Streamlit Docs', 'description': 'A changelog of highlights and fixes for each version of Streamlit.', 'language': 'No language found.'}, page_content='Older versions of Streamlit\\n\\n2024 release notes\\n2023 release notes\\n2022 release notes\\n2021 release notes\\n2020 release notes\\n2019 release notes\\nPrevious: Cheat sheetNext: 2025forumStill have questions?Our forums are full of helpful information and Streamlit experts.HomeContact UsCommunity¬© 2025 Snowflake Inc.Cookie policyforum Ask AI')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split docs\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "document_chunks = text_splitter.split_documents(docs)\n",
    "document_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_chunks[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and load the documents to the vector store\n",
    "\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=document_chunks,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x21b0767d570>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "\n",
    "def _get_context_retriever_chain(vector_db, llm):\n",
    "    retriever = vector_db.as_retriever()\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"user\", \"Given the option/input chosen by the user, mention if the option is correct or not. In both cases, give a short explanation focussing on most recent question.\"),\n",
    "    ])\n",
    "    #log_retriever = retriever.invoke(prompt)\n",
    "\n",
    "    #for logs in log_retriever:\n",
    "\n",
    "        #print(f\"Content of log_retriver: {logs.page_content}\")\n",
    "        #print(f\"Metadata of log_retriver: {logs.metadata}\")\n",
    "\n",
    "    retriever_chain = create_history_aware_retriever(llm, retriever, prompt)\n",
    "\n",
    "    return retriever_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversational_rag_chain(llm):\n",
    "    retriever_chain = _get_context_retriever_chain(vector_db, llm)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "        \"\"\"You are a quiz master that ask questions to user. you will ask user a question and give 4 options. only one opion will be correct.\n",
    "        You will have some context to help with your asking the questions and deciding the correct option, but now always would be completely related or helpful.\n",
    "        You can also use your knowledge to assist answering the user's queries.\\n\n",
    "        {context}\"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ])\n",
    "    stuff_documents_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    print(type(stuff_documents_chain), \" its type\")\n",
    "\n",
    "    return create_retrieval_chain(retriever_chain, stuff_documents_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi there! How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='quiz me', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.runnables.base.RunnableBinding'>  its type\n",
      "Sure! Here's a question for you:\n",
      "\n",
      "Which of the following is a cloud service provided by Amazon Web Services (AWS)?\n",
      "\n",
      "A) Azure DevOps  \n",
      "B) Google Cloud Storage  \n",
      "C) Amazon S3  \n",
      "D) IBM Cloud Functions  \n",
      "\n",
      "What's your answer?"
     ]
    }
   ],
   "source": [
    "# Augmented Generation\n",
    "\n",
    "llm_stream_openai = ChatOpenAI(\n",
    "    model=\"gpt-4o\",  # Here you could use \"o1-preview\" or \"o1-mini\" if you already have access to them\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "llm_stream_anthropic = ChatAnthropic(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "llm_stream = llm_stream_openai  # Select between OpenAI and Anthropic models for the response\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hi\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi there! How can I assist you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"quiz me\"},\n",
    "]\n",
    "messages = [HumanMessage(content=m[\"content\"]) if m[\"role\"] == \"user\" else AIMessage(content=m[\"content\"]) for m in messages]\n",
    "print(messages)\n",
    "\n",
    "conversation_rag_chain = get_conversational_rag_chain(llm_stream)\n",
    "response_message = \"*(RAG Response)*\\n\"\n",
    "for chunk in conversation_rag_chain.pick(\"answer\").stream({\"messages\": messages[:-1], \"input\": messages[-1].content}):\n",
    "    response_message += chunk\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response_message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_v4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
