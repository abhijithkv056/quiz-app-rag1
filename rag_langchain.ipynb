{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_community.document_loaders import (\n",
    "    WebBaseLoader, \n",
    "    PyPDFLoader, \n",
    "    Docx2txtLoader,\n",
    ")\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "os.environ[\"USER_AGENT\"] = \"MyFastAPIApp/1.0\"\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 13\u001b[0m     loader \u001b[38;5;241m=\u001b[39m \u001b[43mPyPDFLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m doc_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.docx\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\abhij\\anaconda3\\envs\\llms_v4\\lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:241\u001b[0m, in \u001b[0;36mPyPDFLoader.__init__\u001b[1;34m(self, file_path, password, headers, extract_images, extraction_mode, extraction_kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpypdf package not found, please install it with `pip install pypdf`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m     )\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m PyPDFParser(\n\u001b[0;32m    243\u001b[0m     password\u001b[38;5;241m=\u001b[39mpassword,\n\u001b[0;32m    244\u001b[0m     extract_images\u001b[38;5;241m=\u001b[39mextract_images,\n\u001b[0;32m    245\u001b[0m     extraction_mode\u001b[38;5;241m=\u001b[39mextraction_mode,\n\u001b[0;32m    246\u001b[0m     extraction_kwargs\u001b[38;5;241m=\u001b[39mextraction_kwargs,\n\u001b[0;32m    247\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\abhij\\anaconda3\\envs\\llms_v4\\lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:117\u001b[0m, in \u001b[0;36mBasePDFLoader.__init__\u001b[1;34m(self, file_path, headers)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path):\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile path \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not a valid file or url\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)\n",
      "\u001b[1;31mValueError\u001b[0m: File path docs\\test_rag.pdf is not a valid file or url",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m         docs\u001b[38;5;241m.\u001b[39mextend(loader\u001b[38;5;241m.\u001b[39mload())\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading document \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdoc_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Load URLs\u001b[39;00m\n\u001b[0;32m     30\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.streamlit.io/develop/quick-reference/release-notes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "# Load docs\n",
    "\n",
    "doc_paths = [\n",
    "    \"docs/test_rag.pdf\"\n",
    "]\n",
    "\n",
    "docs = [] \n",
    "for doc_file in doc_paths:\n",
    "    file_path = Path(doc_file)\n",
    "\n",
    "    try:\n",
    "        if doc_file.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif doc_file.endswith(\".docx\"):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif doc_file.endswith(\".txt\") or doc_file.name.endswith(\".md\"):\n",
    "            loader = TextLoader(file_path)\n",
    "        else:\n",
    "            print(f\"Document type {doc_file.type} not supported.\")\n",
    "            continue\n",
    "\n",
    "        docs.extend(loader.load())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading document {doc_file.name}: {e}\")\n",
    "\n",
    "\n",
    "# Load URLs\n",
    "\n",
    "url = \"https://docs.streamlit.io/develop/quick-reference/release-notes\"\n",
    "try:\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading document from {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split docs\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=1000,\n",
    ")\n",
    "\n",
    "document_chunks = text_splitter.split_documents(docs)\n",
    "document_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and load the documents to the vector store\n",
    "\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=document_chunks,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "\n",
    "def _get_context_retriever_chain(vector_db, llm):\n",
    "    retriever = vector_db.as_retriever()\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"user\", \"Given the option/input chosen by the user, mention if the option is correct or not. Inboth cases, give a short explianation focussing on most recent question.\"),\n",
    "    ])\n",
    "    retriever_chain = create_history_aware_retriever(llm, retriever, prompt)\n",
    "\n",
    "    return retriever_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversational_rag_chain(llm):\n",
    "    retriever_chain = _get_context_retriever_chain(vector_db, llm)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "        \"\"\"You are a quiz master that ask questions to user. you will ask user a question and give 4 options. only one opion will be correct.\n",
    "        You will have some context to help with your asking the questions and deciding the correct option, but now always would be completely related or helpful.\n",
    "        You can also use your knowledge to assist answering the user's queries.\\n\n",
    "        {context}\"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ])\n",
    "    stuff_documents_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    return create_retrieval_chain(retriever_chain, stuff_documents_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Generation\n",
    "\n",
    "llm_stream_openai = ChatOpenAI(\n",
    "    model=\"gpt-4o\",  # Here you could use \"o1-preview\" or \"o1-mini\" if you already have access to them\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "llm_stream_anthropic = ChatAnthropic(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "llm_stream = llm_stream_openai  # Select between OpenAI and Anthropic models for the response\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hi\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi there! How can I assist you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the latest version of Streamlit?\"},\n",
    "]\n",
    "messages = [HumanMessage(content=m[\"content\"]) if m[\"role\"] == \"user\" else AIMessage(content=m[\"content\"]) for m in messages]\n",
    "\n",
    "conversation_rag_chain = get_conversational_rag_chain(llm_stream)\n",
    "response_message = \"*(RAG Response)*\\n\"\n",
    "for chunk in conversation_rag_chain.pick(\"answer\").stream({\"messages\": messages[:-1], \"input\": messages[-1].content}):\n",
    "    response_message += chunk\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response_message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "llm_stream = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZ_OPENAI_ENDPOINT\"),\n",
    "    openai_api_version=\"2024-02-15-preview\",\n",
    "    model_name=\"gpt-4o\",\n",
    "    openai_api_key=os.getenv(\"AZ_OPENAI_API_KEY\"),\n",
    "    openai_api_type=\"azure\",\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "prompt = \"Tell me something about Azure\"\n",
    "\n",
    "for chunk in llm_stream.stream(prompt):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_v4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
